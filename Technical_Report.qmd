---
title: "DATA 624 Project 2: Technical Report"
format: html
author: "Ali Ahmed, Andreina Arias, Kaylie Evans, Naomi Buell, and Zaneta Paulusova"
date: "`r Sys.Date()`"
---

```{r}
#| label: load packages

library(tidyverse)
library(readxl)
library(fpp3)
library(caret)
library(skimr)
library(doParallel)
```

## Instructions

*This is role playing. I am your new boss. I am in charge of production at ABC Beverage and you are a team of data scientists reporting to me. My leadership has told me that new regulations are requiring us to understand our manufacturing process, the predictive factors and be able to report to them our predictive model of PH.*

*Please use the historical data set I am providing. Build and report the factors in BOTH a technical and non-technical report. I like to use Word and Excel. Please provide your non-technical report in a business friendly readable document and your predictions in an Excel readable format. The technical report should show clearly the models you tested and how you selected your final approach.*

*Please submit both Rpubs links and .rmd files or other readable formats for technical and non-technical reports. Also submit the excel file showing the prediction of your models for pH.*

## Introduction

In this technical report, we will analyze the manufacturing process of ABC Beverage to understand the factors that influence the pH level of the product. We will build predictive models to forecast pH levels based on various predictors in the dataset. The goal is to provide insights into the manufacturing process and to create a model that can be used for future predictions.

## Load data

First, we load the data.

```{r}
#| label: load-data

StudentData <- read_excel("StudentData.xlsx") # Training data
StudentEvaluation <- read_excel("StudentEvaluation.xlsx") # Test data
```

We browse the data below.

```{r}
#| label: browse-data

StudentData |> skim()
StudentEvaluation |> skim()
```

## Clean and Tidy Data

Mutate variable types if necessary.

Browse and remove outliers if necessary.

Impute and transform if necessary.

-   Andreina to impute

-   Adreina to check correlation, remove features that have correlation over some threshold

-   Remove near zero variance predictors with `nearZeroVar()`.

## Exploratory Data Analysis

<!--# Ali, since this data is not a time series, we can't do time plots or decomp like we discussed earlier. You can try exploring and plotting the data using `featurePlot(trainingData$x, trainingData$y)`, a correlation plot between all variables with `ggpairs()`, and/or other methods? If relationships between predictors and PH look linear, we'd opt for linear models. If relationships look non-linear, we can try forecasting with non-linear or tree-based models. -Naomi -->

-   Ali to Plot time plot

-   Ali to plot decomposition plot

## Forecast

We will try the following models:

-   Linear regression models:

    -   PLS

    -   Elastic Net

-   Non-linear regression models:

    -   KNN

    -   Multivariate Adaptive Regression Splines (MARS)

-   Tree-based regression models:

    -   Single Tree

    -   Model Tree

Since the data is relatively large, we will avoid heavy models like neural networks, support vector machines (SVM), or boosted trees. Since we have a lot of predictors, we opt for models that handle feature selection or dimensionality reduction like elastic net, PLS, and tree-based models. We also want model results to be easy to interpret for our non-technical report, so we focus on elastic net, MARS, and single/model trees.

<!--# Based on correlation plot in EDA section above, if relationships between predictors and PH look linear, we'd opt for linear models. If relationships look non-linear, we can try forecasting with non-linear or tree-based models. -Naomi -->

Also, because the data is relatively large, we can afford to use a training and a test set.

```{r}
#| label: split-data

StudentData <- StudentData |> drop_na() # <!--NB to DELETE this line after imputation section is completed-->
# Split the data into a training and a test set
trainingRows <- createDataPartition(
    StudentData$PH,
    p = .80,
    list = FALSE
)
StudentData_train <- StudentData[trainingRows, ]
StudentData_test <- StudentData[-trainingRows, ]
```

Since these models take a long time to train, we'll utilize the `doParallel` package for speed.

```{r}
#| label: parallel-processing
#| warning: FALSE
#| message: FALSE

cluster <- makeCluster(
    detectCores() - 1
)

registerDoParallel(
    cluster
)
```

Fitting models to the training data below.

```{r}
#| label: fit-models
```

## Compare model fit and select optimal model

Next, we compare fit and pick model to export.

## Export

```{r}
#| label: Export to Excel

```

## Conclusion

\[RP\]